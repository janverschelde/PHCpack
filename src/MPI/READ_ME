Using MPI with PHCpack version 2.4.72

This directory is entirely new in release 2.2 of PHCpack,
we try to provide a parallel version of PHCpack, using MPI.
It was developed in collaboration with Yusong Wang.
Release 2.3 was extended with parallel pieri.

The parallel monodromy breakup was developed in collaboration
with Anton Leykin, release in 2.3.02, see "mpi2fac_s" and "mpi2fac_d".

Parallel polyhedral homotopies are currently under development
in collaboration with Yan Zhuang, see "mpi2cell*".

Release 2.3.06 has a first version of mpi2track, which does not
-- unlike mpi2phc_s and mpi2phc_d -- read in the entire solution
list at once, but incrementally reads and writes the solutions.
For large systems, mpi2track is recommended.

The makefile in this directory can be used to create "adatest",
which is a short sanity check on the whole compilation system.
The main program in "adatest" is compiled by the MPI compiler
with calls to object files created by the gnu-ada compiler.
Type "make adatest" to create and "mpirun -np 1 adatest" to run.

The makefile in the Objects directory of PHCpack is needed to create
the other programs.  The main program is mpi2phc.c.

The first version of mpi2phc.c is a very simple parallel path tracker:
the program reads in a target and a start system (the input file for
the start system must contain the start solutions), and distributes
the start solutions evenly among the available processors.
After the path tracking is done, the root node prints out all solutions
to screen (a redirection of output with > is recommended for large outputs).

A second version uses dynamic load balancing.  Static load balancing
works well if all paths require the same amount of time, while dynamic
load balancing is good when there is a large variation in the time it
takes to trace paths.

The parallel subsystem-by-subsystem solver was developed in
collaboration in Yun Guan.

-------------------------------------------------------------------------------
file name                        : short description
-------------------------------------------------------------------------------
hello.adb                        : ada procedure "Hello World"
call_hello.c                     : C function which calls the ada procedure
adatest.c                        : MPI main program
-------------------------------------------------------------------------------
mpi2sys.c                        : broadcasting a polynomial system 
mpi2sol.c                        : broadcasting a list of solutions
mpi2hom.c                        : broadcasting a homotopy + start solutions
mpi2phc_s.c                      : static distribution of paths over nodes
mpi2phc_d.c                      : dynamic distribution of paths over nodes
mpi2phc_d2.c                     : dynamic version with overlapping 
mpi2phc_dd.c                     : double double version of mpi2phc_d2
mpi2phc_qd.c                     : quad double version of mpi2phc_d2
mpi2track.c                      : tracking with incremental read/write
-------------------------------------------------------------------------------
tree.c                           : Pieri tree for the combinatorial root count
ts_tree.c                        : test on trees
queue                            : queue of jobs
parallel_tree.c                  : tree to be used by parallel_pieri
parallel_pieri.c                 : parallel implementation of Pieri homotopies
-------------------------------------------------------------------------------
parallel_phcpack                 : utilities for parallel path tracking
parallel_monodromy               : function for parallel monodromy
mpi2fac.c                        : parallel monodromy breakup, version 0
mpi2fac_s.c                      : static load distribution rewrites mpi2fac.c
manage_components                : functions needed for mpi2fac_d
mpi2fac_d.c                      : dynamic parallel monodromy breakup
-------------------------------------------------------------------------------
parallel_cells.c                 : utilities for distributing mixed cells
mpi2cell_s.c                     : static load balancing, upgrade of mpi2cell
mpi2cell_d.c                     : dynamic load balancing version mpi2cell
-------------------------------------------------------------------------------
job_queue                        : manages queue of jobs
idle_queue                       : manages queue of idle workers
from_mpi2track                   : utilities from mpi2track
parallel_subsystem               : parallel subsystem-by-subsystem solver
-------------------------------------------------------------------------------
mpi2padcon                       : pade continuation in parallel
-------------------------------------------------------------------------------
